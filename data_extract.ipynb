{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(path):\n",
    "    pdf=PdfFileReader(path)\n",
    "    number_pages=pdf.getNumPages()\n",
    "    content=''\n",
    "    for i in range(number_pages):\n",
    "        content+=pdf.getPage(i).extractText()\n",
    "    \n",
    "    content=content.replace('\\\\n','. ').replace('\\n\\n','. ')\n",
    "    content=content.replace('\\n','. ')\n",
    "    content=content.replace('\\t',' ')\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path to each pdf file stored in folder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_path_pdf(path_folder):\n",
    "    path_pdf=[]\n",
    "    for dirname,_,filenames in os.walk(path_folder):\n",
    "        for filename in filenames:\n",
    "            path_pdf.append(os.path.join(dirname,filename))\n",
    "    return path_pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_JD=\"./JD/\"\n",
    "path_2_pdfJD=get_path_pdf(path_JD)\n",
    "content_JD=extract_pdf(path_2_pdfJD[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CV=\"./CV/\"\n",
    "path_2_pdfCV=get_path_pdf(path_CV)\n",
    "content_CV=[]\n",
    "for p in path_2_pdfCV:\n",
    "    content_CV.append(extract_pdf(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spacy to extract skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "import jsonlines\n",
    "import spacy\n",
    "import re \n",
    "import pyperclip\n",
    "from sympy import true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"skill_paterns.jsonl\"\n",
    "\n",
    "with jsonlines.open(json_path) as f:\n",
    "    entities=[line[\"label\"].upper() for line in f.iter()]\n",
    "\n",
    "# spacy model\n",
    "nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x258c15f1fc0>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERSONAL INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKILL    : ['CSS', 'Software', 'API', 'Javascript', 'languages', 'Programming Language', 'HTML', 'LANGUAGES', 'software', 'VueJS']\n",
      "GPA      : None\n",
      "Ex       : None\n",
      "\n",
      "EDU      : ACADEMIC HISTORY\n",
      "Personal Website : None\n",
      "GIT      : None\n",
      "Linkedin : None\n",
      "Mail     : phanhoangphuc123321@gmail.com\n",
      "Phone    : None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MAY 2018 - PRESENT. Information Technology.THU DUC TECHNOLOGY COLLEGEACADEMIC HISTORY. - Programming Language: HTML, CSS, Javascript,  .   Ant Design Vue.  . - Knowledge: UX/UI, ReactJS, VueJS, .   GraphQL, RESTful API.     . - Teamworking.. - Highly responsible.. - Well-organized and disciplined.SKILLS. - Reading.. - Learning foreign languages.. - Playing soccer and gym.INTERESTS. - Vietnamese.. - English.LANGUAGES. - Phone: +84 786 572 491.. - Email: phanhoangphuc123321@gmail.com.. - Address: Quarter 6, Linh Trung Ward, Thu Duc. -. - District, Ho Chi Minh City, Vietnam.CONTACT INFO. - In my mind, learning through working is the most. important factor in my career path. That is the. reason why Iâ€™m looking for a opportunity at web. field company, to dedicate, and also. improve myself.ABOUT ME. ICT24H CO., LTD / Jun 2020 - Present. - Online Exam Software.. Project: Create Online Exam Software.. Description: This software could help. administrators creating exams quickly, save the. test history and related information. Then test. takers can take the exam and submit online.. Responsibility: Front-End Developer.. Technology used: VueJS, Ant Design Vue.. - Majority management.. Project: Managing company documents.. Description: Information archiving, reporting                   . statistics and digitizing approval process for the. company.. Responsibility: Front-End Developer.. Technology used: VueJS, Ant Design Vue.. - Personal Project.. - Project: Snake Game.. Description: Traditional snake game for everyone.. The player controls a long, thin snake, which. roams around on a bordered plane, picking up. food, trying to avoid hitting its own tail or the. edges of the area.. Responsibility: Front-End Developer.. Technology used: ReactJS.. - Project: Interface of Personal Blog.. Description: Display the posts and post it to the. personal blog.. Responsibility: Front-End Developer.. Technology used: ReactJS, HTML, CSS.EXPERIENCESPHAN VAN PHUC EM'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_skill(content_CV):\n",
    "    doc=nlp(content_CV)\n",
    "    skill_list=[]\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='SKILL':\n",
    "            skill_list.append(ent.text)\n",
    "    skill_list=list(set(skill_list))\n",
    "    return skill_list\n",
    "\n",
    "def get_GPA(content_CV):\n",
    "    doc=nlp(content_CV)\n",
    "    sent=list(doc.sents)\n",
    "    gpa=''\n",
    "    for s in sent:\n",
    "        s=s.text\n",
    "        if s.find('GPA') !=-1 :\n",
    "            gba_pos= s.find('GPA') \n",
    "            for i in range (gba_pos+3,gba_pos+8):\n",
    "                if (s[i] >'0' and s[i]<'9' or s[i]=='.'):\n",
    "                    gpa+=s[i]\n",
    "    if gpa=='':\n",
    "        return None\n",
    "    else:\n",
    "        return gpa\n",
    "\n",
    "def get_experience(content_CV):\n",
    "    '''\n",
    "    Return\\n\n",
    "        None if no experience\\n\n",
    "        List of experience if exist\n",
    "    '''\n",
    "    doc=nlp(content_CV)\n",
    "    sent=list(doc.sents)\n",
    "    final_res=''\n",
    "    ex=[]\n",
    "    for s in sent:\n",
    "        s_text=s.text.split(' ')\n",
    "        flag=False\n",
    "        for i in s_text:\n",
    "            i=i.lower()\n",
    "            if i=='experience' or i=='project':\n",
    "                flag=True\n",
    "        if flag==True:\n",
    "            ex.append([s.text])\n",
    "    if (len(ex)==0):\n",
    "        final_res=None\n",
    "    else:\n",
    "        final_res=ex\n",
    "    return final_res\n",
    "\n",
    "def get_education(content_CV):\n",
    "    doc=nlp(content_CV)\n",
    "    sent=list(doc.sents)\n",
    "    edu=''\n",
    "    pos_edu=-1\n",
    "    pos_edu_end=-1\n",
    "    for s in sent:\n",
    "        s_text=s.text.lower()\n",
    "        flag=False\n",
    "        if s_text.find('education')!=-1 or s_text.find('university')!=-1 or s_text.find('academic')!=-1:\n",
    "            edu =s.text\n",
    "            if s_text.find('education')!=-1:\n",
    "                pos_edu=s_text.find('education')+9\n",
    "            if s_text.find('academic') !=-1 :\n",
    "                pos_edu=s_text.find('academic')\n",
    "            else:\n",
    "                pos_edu=s_text.find('university')\n",
    "            \n",
    "            pos_edu_end=s_text.find('. ',pos_edu)\n",
    "            edu=edu[pos_edu:pos_edu_end]\n",
    "    if edu=='':\n",
    "        return None\n",
    "    else:\n",
    "        return edu\n",
    "\n",
    "def get_phone(content_CV):\n",
    "    '''\n",
    "    Format for Phone-Numbers:\n",
    "    134567890\n",
    "    123-456-7890\n",
    "    (123)(456)(7890)\n",
    "    123.456.7890\n",
    "    (123)(456-7890)\n",
    "    '''\n",
    "    phone= re.compile(r'''\n",
    "        (\\d{3}|\\(\\d{3}\\))    \n",
    "        (\\s|-|\\.)?           \n",
    "        (\\d{3}|\\(\\d{3}\\))    \n",
    "        (\\s|-|\\.)?           \n",
    "        (\\d{4}|\\(\\d{4}\\))    \n",
    "    ''', re.VERBOSE) \n",
    "    matchs=phone.finditer(content_CV)\n",
    "    res = ''\n",
    "    for match in matchs:\n",
    "        res+=match.group(0)\n",
    "    if res=='':\n",
    "        return None\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def get_link(link,content_CV):\n",
    "    matchs=link.finditer(content_CV)\n",
    "    res=''\n",
    "    for match in matchs:\n",
    "        res+=match.group(0)\n",
    "    if res=='':\n",
    "        return None\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "test=content_CV[0]\n",
    "print('SKILL    :',get_skill(test))\n",
    "print('GPA      :',get_GPA(test))       \n",
    "print('Ex       :',get_experience(test))\n",
    "print()\n",
    "print('EDU      :',get_education(test))\n",
    "print('Personal Website :',get_link(web,test))\n",
    "print('GIT      :',get_link(git,test))\n",
    "print('Linkedin :',get_link(linkedin,test))\n",
    "print('Mail     :',get_link(mail,test))\n",
    "\n",
    "print('Phone    :',get_phone(test))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON    Linh Trung Ward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linh Trung Ward'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# initialize matcher with a vocab\n",
    "\n",
    "def extract_name(content_CV):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    doc=nlp(content_CV)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='PERSON':\n",
    "            print(ent.label_,'  ',ent.text)\n",
    "            return(ent.text)\n",
    "            \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'},{'POS': 'PROPN'}]\n",
    "    matcher.add('NAME',[pattern])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text\n",
    "        \n",
    "    return None\n",
    "\n",
    "extract_name(content_CV[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Accuracy of name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('./data/training/train_data.json','rb')) \n",
    "\n",
    "def name_acc(train_data):\n",
    "    list_an=[]\n",
    "    list_txt=[]\n",
    "    name=[]\n",
    "\n",
    "    for text,annotation in train_data:\n",
    "        list_an.append(list(annotation.values()))\n",
    "        list_txt.append(text)\n",
    "\n",
    "    target_name=[]\n",
    "    predic_name=[]\n",
    "\n",
    "    similar=0\n",
    "    for i in range(len(list_an)):\n",
    "        t=''\n",
    "        p=''\n",
    "        p=extract_name(list_txt[i])\n",
    "        predic_name.append(p)\n",
    "        for j in range(len(list_an[i][0])):\n",
    "            if list_an[i][0][j][2]=='Name':\n",
    "                t=list_txt[i][list_an[i][0][j][0]:list_an[i][0][j][1]]\n",
    "                target_name.append(t)\n",
    "        if t==p:\n",
    "            similar+=1\n",
    "    return (similar/len(list_an)*100)    \n",
    "name_acc(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final extract and save to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone number</th>\n",
       "      <th>related link(git,web,linkedin)</th>\n",
       "      <th>skill</th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, name, email, phone number, related link(git,web,linkedin), skill, experience, education]\n",
       "Index: []"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=['ID','name','email','phone number','related link(git,web,linkedin)','skill','experience','education','GPA']\n",
    "df_information = pd.DataFrame(columns=label) \n",
    "df_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON    Linh Trung Ward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8824\\2885845269.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON    Chi Minh City\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8824\\2885845269.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON    Volunteer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8824\\2885845269.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON    Phan Thi Bich Ngoc Curriculum Vitae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8824\\2885845269.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone number</th>\n",
       "      <th>related link(git,web,linkedin)</th>\n",
       "      <th>skill</th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Linh Trung Ward</td>\n",
       "      <td>phanhoangphuc123321@gmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[CSS, Software, API, Javascript, languages, Pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>[None, ACADEMIC HISTORY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chi Minh City</td>\n",
       "      <td>nguyenkhavi01032001@gmail.com</td>\n",
       "      <td>0374246292</td>\n",
       "      <td>[gitlab.com/nguyenkhavi., None, linkedin.com/i...</td>\n",
       "      <td>[natural language processing, API, mobile, NLP...</td>\n",
       "      <td>[[A software developer with 1+ year of experie...</td>\n",
       "      <td>[8.3, University of Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Volunteer</td>\n",
       "      <td>levietdc01@gmail.com</td>\n",
       "      <td>0396024273</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[Visual Studio Code, Hadoop, Computer Vision, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[81, University of Science, majoring in Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Phan Thi Bich Ngoc Curriculum Vitae</td>\n",
       "      <td>Ptbichngoc2502@gmail.com</td>\n",
       "      <td>0347297090</td>\n",
       "      <td>[None, None, linkedin.com/in/bich-ngoc-0ab1831...</td>\n",
       "      <td>[Computer vision, database, OpenGL, SQL, CERTI...</td>\n",
       "      <td>[[guide on the various steps a project goes th...</td>\n",
       "      <td>[7.5, University of Science]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID                                 name                          email  \\\n",
       "0  0                      Linh Trung Ward  phanhoangphuc123321@gmail.com   \n",
       "1  1                        Chi Minh City  nguyenkhavi01032001@gmail.com   \n",
       "2  2                            Volunteer           levietdc01@gmail.com   \n",
       "3  3  Phan Thi Bich Ngoc Curriculum Vitae       Ptbichngoc2502@gmail.com   \n",
       "\n",
       "  phone number                     related link(git,web,linkedin)  \\\n",
       "0         None                                 [None, None, None]   \n",
       "1   0374246292  [gitlab.com/nguyenkhavi., None, linkedin.com/i...   \n",
       "2   0396024273                                 [None, None, None]   \n",
       "3   0347297090  [None, None, linkedin.com/in/bich-ngoc-0ab1831...   \n",
       "\n",
       "                                               skill  \\\n",
       "0  [CSS, Software, API, Javascript, languages, Pr...   \n",
       "1  [natural language processing, API, mobile, NLP...   \n",
       "2  [Visual Studio Code, Hadoop, Computer Vision, ...   \n",
       "3  [Computer vision, database, OpenGL, SQL, CERTI...   \n",
       "\n",
       "                                          experience  \\\n",
       "0                                               None   \n",
       "1  [[A software developer with 1+ year of experie...   \n",
       "2                                               None   \n",
       "3  [[guide on the various steps a project goes th...   \n",
       "\n",
       "                                           education  \n",
       "0                           [None, ACADEMIC HISTORY]  \n",
       "1                       [8.3, University of Science]  \n",
       "2  [81, University of Science, majoring in Comput...  \n",
       "3                       [7.5, University of Science]  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_all_data(list_content_CV, df):\n",
    "    mail = re.compile(r'[a-zA-Z0-9-\\.]+@[a-zA-Z-\\.]*\\.(com|edu|net)')\n",
    "    git = re.compile(r'(gitlab.com/|github.com/)+[a-zA-Z0-9-\\.]*')\n",
    "    web = re.compile(r'(http://|https:// )+[a-zA-Z0-9-\"/\"-\\.]*')\n",
    "    linkedin = re.compile(r'linkedin.com/+[a-zA-Z0-9-\"/\"-\\.]*')\n",
    "\n",
    "    for i in range(len(list_content_CV)):\n",
    "        content=list_content_CV[i]\n",
    "        link=[]\n",
    "        link.append(get_link(git,content))\n",
    "        link.append(get_link(web,content))\n",
    "        link.append(get_link(linkedin,content))\n",
    "        r = {\n",
    "            'ID': i,\n",
    "            'name': extract_name(content),\n",
    "            'email': get_link(mail,content),\n",
    "            'phone number': get_phone(content),\n",
    "            'related link(git,web,linkedin)': link,\n",
    "            'skill': get_skill(content),\n",
    "            'experience': get_experience(content),\n",
    "            'education': get_education(content)\n",
    "            'GPA':get_GPA(content)\n",
    "            }\n",
    "\n",
    "        df = df.append(r, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "extract_all_data(content_CV,df_information)\n",
    "# test=content_CV[4]\n",
    "# print(get_GPA(test))       \n",
    "# print(get_experience(test))\n",
    "# print()\n",
    "# print(get_education(test))\n",
    "# print(get_link(web,test))\n",
    "# print(get_link(git,test))\n",
    "# print(get_link(linkedin,test))\n",
    "# print(get_link(mail,test))\n",
    "# print(get_skill(test))\n",
    "# get_phone(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load accuracy name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model=spacy.load('nlp_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn to calculate the cosine similarity score of CV and JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [264], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# def cosine_similarity(list_CV,JD):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#     test=[list_CV]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test\u001b[39m=\u001b[39m[content_CV,content_JD]\n\u001b[1;32m----> 4\u001b[0m count_matrix\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mfit_transform(test)\n\u001b[0;32m      5\u001b[0m cosine_similarity(count_matrix)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1323\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1325\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1327\u001b[0m             )\n\u001b[0;32m   1328\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1330\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1333\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1200\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1201\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1202\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1203\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:71\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 71\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# def cosine_similarity(list_CV,JD):\n",
    "#     test=[list_CV]\n",
    "test=[content_CV,content_JD]\n",
    "count_matrix=cv.fit_transform(test)\n",
    "cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4040562886306343"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[content_CV[4],content_JD]\n",
    "count_matrix=cv.fit_transform(test)\n",
    "match=cosine_similarity(count_matrix)\n",
    "match[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x244 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 244 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "231b793e72510f63263cf75731d759da8776d8c74c3ed2dbefa0f0827e58fa6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
