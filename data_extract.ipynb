{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(path):\n",
    "    pdf=PdfFileReader(path)\n",
    "    number_pages=pdf.getNumPages()\n",
    "    content=''\n",
    "    for i in range(number_pages):\n",
    "        content+=pdf.getPage(i).extractText()\n",
    "    \n",
    "    content=content.replace('\\\\n',' ').replace('\\n\\n',' ')\n",
    "    content=content.replace('\\n',' ')\n",
    "    content=content.replace('\\t',' ')\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path to each pdf file stored in folder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_path_pdf(path_folder):\n",
    "    path_pdf=[]\n",
    "    for dirname,_,filenames in os.walk(path_folder):\n",
    "        for filename in filenames:\n",
    "            path_pdf.append(os.path.join(dirname,filename))\n",
    "    return path_pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_JD=\"./JD/\"\n",
    "path_2_pdfJD=get_path_pdf(path_JD)\n",
    "content_JD=extract_pdf(path_2_pdfJD[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CV=\"./CV/\"\n",
    "path_2_pdfCV=get_path_pdf(path_CV)\n",
    "content_CV=[]\n",
    "for p in path_2_pdfCV:\n",
    "    content_CV.append(extract_pdf(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spacy to extract skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "import jsonlines\n",
    "import spacy\n",
    "import re \n",
    "import pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"skill_paterns.jsonl\"\n",
    "\n",
    "with jsonlines.open(json_path) as f:\n",
    "    entities=[line[\"label\"].upper() for line in f.iter()]\n",
    "\n",
    "# spacy model\n",
    "nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'entity_ruler']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(json_path)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer vision',\n",
       " 'computer science',\n",
       " 'Python',\n",
       " 'OpenGL',\n",
       " 'CERTIFICATE',\n",
       " 'ML',\n",
       " 'Google',\n",
       " 'OpenCV',\n",
       " 'database',\n",
       " 'Deep Learning',\n",
       " 'languages',\n",
       " 'SQL',\n",
       " 'data structure',\n",
       " 'Computer Science',\n",
       " 'algorithm',\n",
       " 'Numpy',\n",
       " 'C',\n",
       " 'C++',\n",
       " 'design']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=nlp(content_CV[0])\n",
    "\n",
    "def get_skill(doc):\n",
    "    skill_list=[]\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='SKILL':\n",
    "            skill_list.append(ent.text)\n",
    "    skill_list=list(set(skill_list))\n",
    "    return skill_list\n",
    "    \n",
    "get_skill(doc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Personal infomation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "None\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bachelor of Computer Science (Current GPA: 7.5/10) 2019-2023 University of Science Learn the computer science foundation knowledge such as programing languages, database, data structure and algorithm, math, Computer vision, Machine learning, AI, Recognition SKILLS Framework/Libraries OpenCV, Numpy, Pytorch, OpenGL Language C/C++, Python, C#, SQL Soft Skills Teamwork, Presentation, English (Upper Intermediate) PROJECTS March 2022MNIST'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import true\n",
    "\n",
    "\n",
    "doc=nlp(content_CV[0])\n",
    "\n",
    "def get_GPA(doc):\n",
    "    sent=list(doc.sents)\n",
    "    gpa=''\n",
    "    for s in sent:\n",
    "        s=s.text\n",
    "        if s.find('GPA') !=-1 :\n",
    "            gba_pos= s.find('GPA') \n",
    "            for i in range (gba_pos+3,gba_pos+8):\n",
    "                if (s[i] >'0' and s[i]<'9' or s[i]=='.'):\n",
    "                    gpa+=s[i]\n",
    "    return gpa\n",
    "\n",
    "def get_experience(doc):\n",
    "    '''\n",
    "    Return\\n\n",
    "        None if no experience\\n\n",
    "        List of experience if exist\n",
    "    '''\n",
    "    sent=list(doc.sents)\n",
    "    final_res=''\n",
    "    ex=[]\n",
    "    for s in sent:\n",
    "        s_text=s.text.split(' ')\n",
    "        flag=False\n",
    "        for i in s_text:\n",
    "            i=i.lower()\n",
    "            if i=='experience':\n",
    "                flag=True\n",
    "        if flag==True:\n",
    "            ex.append([s.text])\n",
    "    if (len(ex)==0):\n",
    "        final_res=None\n",
    "    else:\n",
    "        final_res=ex\n",
    "    return final_res\n",
    "\n",
    "def get_education(doc):\n",
    "    sent=list(doc.sents)\n",
    "    edu=''\n",
    "    pos_edu=-1\n",
    "    for s in sent:\n",
    "        s_text=s.text.lower()\n",
    "        flag=False\n",
    "        if s_text.find('education')!=-1 or s_text.find('university')!=-1:\n",
    "            edu =s.text\n",
    "            if s_text.find('education')!=-1:\n",
    "                pos_edu=s_text.find('education')\n",
    "            else:\n",
    "                pos_edu=s_text.find('university')\n",
    "            \n",
    "            edu=edu[pos_edu+10:]\n",
    "    return edu\n",
    "\n",
    "print(get_GPA(doc))       \n",
    "print(get_experience(doc))\n",
    "print()\n",
    "print(get_education(doc))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERSONAL INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "linkedin.com/in/bich-ngoc-0ab1831b3\n",
      "Ptbichngoc2502@gmail.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0347297090'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = content_CV[0]\n",
    "mail = re.compile(r'[a-zA-Z0-9-\\.]+@[a-zA-Z-\\.]*\\.(com|edu|net)')\n",
    "git = re.compile(r'(gitlab.com/|github.com/)+[a-zA-Z0-9-\\.]*')\n",
    "web = re.compile(r'(http://|https:// )+[a-zA-Z0-9-\"/\"-\\.]*')\n",
    "linkedin = re.compile(r'linkedin.com/+[a-zA-Z0-9-\"/\"-\\.]*')\n",
    "\n",
    "def get_phone():\n",
    "    '''\n",
    "    Format for Phone-Numbers:\n",
    "    134567890\n",
    "    123-456-7890\n",
    "    (123)(456)(7890)\n",
    "    123.456.7890\n",
    "    (123)(456-7890)\n",
    "    '''\n",
    "    phone= re.compile(r'''\n",
    "        (\\d{3}|\\(\\d{3}\\))    \n",
    "        (\\s|-|\\.)?           \n",
    "        (\\d{3}|\\(\\d{3}\\))    \n",
    "        (\\s|-|\\.)?           \n",
    "        (\\d{4}|\\(\\d{4}\\))    \n",
    "    ''', re.VERBOSE) \n",
    "    \n",
    "    matchs=phone.finditer(test)\n",
    "    res = ''\n",
    "    for match in matchs:\n",
    "        res+=match.group(0)\n",
    "    return res\n",
    "\n",
    "def get_link(link):\n",
    "    matchs=link.finditer(test)\n",
    "    res=''\n",
    "    for match in matchs:\n",
    "        res+=match.group(0)\n",
    "    return res\n",
    "\n",
    "print(get_link(web))\n",
    "print(get_link(git))\n",
    "print(get_link(linkedin))\n",
    "print(get_link(mail))\n",
    "get_phone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phan Thi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "def extract_name(content_CV):\n",
    "    doc=nlp(content_CV)\n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    matcher.add('NAME',[pattern])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "extract_name(content_CV[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model=spacy.load('nlp_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(doc):\n",
    "    result=''\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_=='PERSON':\n",
    "            result=f'{ent.label_.upper():{30}}-{ent.text}'\n",
    "        break\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Accuracy of name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Govardhana K',\n",
       " 'Harini Komaravelli',\n",
       " 'Hartej Kathuria',\n",
       " 'Ijas Nizamuddin',\n",
       " 'Imgeeyaul Ansari',\n",
       " 'Jay Madhavi',\n",
       " 'Jitendra Babu',\n",
       " 'Jyotirbindu Patnaik',\n",
       " 'Karthihayini C',\n",
       " 'Karthik GV',\n",
       " 'Kartik Sharma',\n",
       " 'Kasturika Borah',\n",
       " 'Kavitha K',\n",
       " 'Kavya U.',\n",
       " 'Khushboo Choudhary',\n",
       " 'kimaya sonawane',\n",
       " 'Koushik Katta',\n",
       " 'Kowsick Somasundaram',\n",
       " 'Lakshika Neelakshi',\n",
       " 'Madas Peddaiah',\n",
       " 'Madhuri Sripathi',\n",
       " 'Mahesh Vijay',\n",
       " 'Manisha Bharti',\n",
       " 'Manjari Singh',\n",
       " 'Mohamed Ameen',\n",
       " 'Mohini Gupta',\n",
       " 'Navas Koya',\n",
       " 'Navjyot Singh Rathore',\n",
       " 'Nazish Alam',\n",
       " 'Nidhi Pandit',\n",
       " 'Nikhileshkumar Ikhar',\n",
       " 'Nitin Tr',\n",
       " 'Pradeeba V',\n",
       " 'Prakriti Shaurya',\n",
       " 'PRASHANTH BADALA',\n",
       " 'Pratibha P',\n",
       " 'Prem Koshti',\n",
       " 'Pulkit Saxena',\n",
       " 'Puneet Singh',\n",
       " 'Rahul Bollu',\n",
       " 'Rajeev Kumar',\n",
       " 'Ram Edupuganti',\n",
       " 'Ramesh HP',\n",
       " 'Ramya. P',\n",
       " 'R Arunravi',\n",
       " 'Ravi Shankar',\n",
       " 'Ravi Shivgond',\n",
       " 'Rohit Bijlani',\n",
       " 'Roshan Sinha',\n",
       " 'Sai Dhir',\n",
       " 'Sai Patha',\n",
       " 'Sai Vivek Venkatraman',\n",
       " 'Sameer Kujur',\n",
       " 'Samyuktha Shivakumar',\n",
       " 'Santosh Ganta',\n",
       " 'Sarfaraz Ahmad',\n",
       " 'Senthil Kumar',\n",
       " 'Shabnam Saba',\n",
       " 'Shaheen Unissa',\n",
       " 'Sharan Adla',\n",
       " 'Shreyanshu Gupta',\n",
       " 'Shrishti Chauhan',\n",
       " 'Shubham Mittal',\n",
       " 'Sivaganesh Selvakumar',\n",
       " 'Snehal Jadhav',\n",
       " 'Soumya Balan',\n",
       " 'Soumya Balan',\n",
       " 'Soumya Balan',\n",
       " 'Sowmya Karanth',\n",
       " 'Srabani Das',\n",
       " 'Srinivas VO',\n",
       " 'Srushti Bhadale',\n",
       " 'Sudaya Puranik',\n",
       " 'Sumit Kubade',\n",
       " 'Syam Devendla',\n",
       " 'Tejasri Gunnam',\n",
       " 'Urshila Lohani',\n",
       " 'Vamsi krishna',\n",
       " 'VARUN AHLUWALIA',\n",
       " 'Vijayalakshmi Govindarajan',\n",
       " 'Vijayalakshmi Govindarajan',\n",
       " 'Vikas Singh',\n",
       " 'Yasothai Jayaramachandran',\n",
       " 'Yathishwaran P',\n",
       " 'Yogi Pesaru',\n",
       " 'Anurag Asthana',\n",
       " 'Syed Sadath ali',\n",
       " 'Nida Khan',\n",
       " 'Fenil Francis',\n",
       " 'Gaurav Soni',\n",
       " 'Viny Khandelwal',\n",
       " 'Viny Khandelwal',\n",
       " 'amarjyot sodhi',\n",
       " 'Sameer Kujur',\n",
       " 'Zaheer Uddin',\n",
       " 'Abdul B',\n",
       " 'Bike Rally',\n",
       " 'Girish Acharya',\n",
       " 'Asha Subbaiah',\n",
       " 'Divesh Singh',\n",
       " 'Ramesh chokkala',\n",
       " 'Ganesh AlalaSundaram',\n",
       " 'Srinu Naik Ramavath',\n",
       " 'Puneet Bhandari',\n",
       " 'Aarti Pimplay',\n",
       " 'Bangalore Tavarekere',\n",
       " 'Avani Priya',\n",
       " 'Sanand Pal',\n",
       " 'Partho Sarathi Mitra',\n",
       " 'Pranay Sathu',\n",
       " 'Tanmoy Maity',\n",
       " 'Aanirudh Razdan',\n",
       " 'Shiksha Bhatnagar',\n",
       " 'Chhaya Prabhale',\n",
       " 'Karthik G V',\n",
       " 'Mohammed Murtuza',\n",
       " 'Saurabh Saurabh',\n",
       " 'Prabhu Prasad Mohapatra',\n",
       " 'Raja Chandra Mouli',\n",
       " 'Krishna Prasad',\n",
       " 'Dushyant Bhatt',\n",
       " 'Soumya Balan',\n",
       " 'pradeep chauhan',\n",
       " 'pradeep chauhan',\n",
       " 'e: (Akansha',\n",
       " 'Akansha Jain',\n",
       " 'Rishabh soni',\n",
       " 'Paul Rajiv',\n",
       " 'Karan Turkar',\n",
       " 'Akshay Dubey',\n",
       " 'Sayani Goswami',\n",
       " 'Sweety Garg',\n",
       " 'Ramkrishan Bhatt',\n",
       " 'B. Gokul',\n",
       " 'Anand S',\n",
       " 'Krishna Prasad',\n",
       " 'Saurabh Sandhikar',\n",
       " 'Priyesh Dubey',\n",
       " 'Laya A',\n",
       " 'Vishwanath P',\n",
       " 'Hemil Bhavsar',\n",
       " 'Siddhartha Chetri',\n",
       " 'Pratik Vaidya',\n",
       " 'Ramakrishna Rao',\n",
       " 'Keshav Dhawale',\n",
       " 'Praveen Bhaskar',\n",
       " 'Gunjan Nayyar',\n",
       " 'Rupesh Reddy',\n",
       " 'Puneeth R',\n",
       " 'Kandrapu Reddy',\n",
       " 'Vineeth Vijayan',\n",
       " 'Rahul Tayade',\n",
       " 'Debasish Dasgupta',\n",
       " 'Suresh Kanagala',\n",
       " 'Jaspreet Kaur',\n",
       " 'Somanath Behera',\n",
       " 'Ashish Indoriya',\n",
       " 'Dilliraja Baskara',\n",
       " 'Deepika S',\n",
       " 'Jacob Philip',\n",
       " 'Yogesh Ghatole',\n",
       " 'Shaik Tazuddin',\n",
       " 'Angad Waghmare',\n",
       " 'Sohan Dhakad',\n",
       " 'Madhava Konjeti',\n",
       " 'Shreya Agnihotri',\n",
       " 'Tapan kumar Nayak',\n",
       " 'Arpit Jain',\n",
       " 'Palani S',\n",
       " 'Meenalochani Kondya',\n",
       " 'Shrinidhi Selva Kumar',\n",
       " 'Mayank Shukla',\n",
       " 'Shraddha Achar',\n",
       " 'Arpit Godha',\n",
       " 'Jatin Arora',\n",
       " 'Karthik Gururaj',\n",
       " 'Akila Mohideen',\n",
       " 'Ahmad Bardolia',\n",
       " 'Puran Mal',\n",
       " 'Sridevi H',\n",
       " 'Raktim Podder',\n",
       " 'Pavithra M',\n",
       " 'shrikant desai',\n",
       " 'Kiran Kumar',\n",
       " 'Chaban kumar Debbarma',\n",
       " 'Akash Gulhane',\n",
       " 'K. Siddharth',\n",
       " 'Shivam Rathi',\n",
       " 'Nitin Verma',\n",
       " 'Venkateswara D',\n",
       " 'Shivasai Mantri',\n",
       " 'Prasanna Ignatius',\n",
       " 'Pankaj Bhosale',\n",
       " 'Vinay Singhal',\n",
       " 'Pawan Nag',\n",
       " 'Pawan Nag',\n",
       " 'Shivam Sharma',\n",
       " 'Gaikwad Dilip',\n",
       " 'Moumita Mitra',\n",
       " 'Suman Biswas',\n",
       " 'Mansi Thanki',\n",
       " 'Anil Kumar',\n",
       " 'Siddharth Choudhary',\n",
       " 'Valarmathi Dhandapani',\n",
       " 'Pradeep Kumar']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = json.load(open('./data/training/train_data.json','rb')) \n",
    "list_an=[]\n",
    "list_txt=[]\n",
    "name=[]\n",
    "for text,annotation in train_data:\n",
    "    list_an.append(list(annotation.values()))\n",
    "    list_txt.append(text)\n",
    "\n",
    "name=[]\n",
    "for i in range(len(list_an)):\n",
    "    for j in range(len(list_an[i][0])):\n",
    "        if list_an[i][0][j][2]=='Name':\n",
    "            name.append(list_txt[i][list_an[i][0][j][0]:list_an[i][0][j][1]])\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn to calculate the cosine similarity score of CV and JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "test=[content_CV[2],content_JD]\n",
    "count_matrix=cv.fit_transform(test)\n",
    "cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x314 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "231b793e72510f63263cf75731d759da8776d8c74c3ed2dbefa0f0827e58fa6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
